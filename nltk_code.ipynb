{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667fcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk-LookupError错误：https://blog.csdn.net/yeshang_lady/article/details/105885533"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2041194",
   "metadata": {},
   "source": [
    "## 小试牛刀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "873dbe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eed81e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"It's a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries, and an active discussion forum.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ed8a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba6eed1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', \"'s\", 'a', 'leading', 'platform', 'for', 'building', 'Python', 'programs', 'to', 'work', 'with', 'human', 'language', 'data', '.', 'It', 'provides', 'easy-to-use', 'interfaces', 'to', 'over', '50', 'corpora', 'and', 'lexical', 'resources', 'such', 'as', 'WordNet', ',', 'along', 'with', 'a', 'suite', 'of', 'text', 'processing', 'libraries', 'for', 'classification', ',', 'tokenization', ',', 'stemming', ',', 'tagging', ',', 'parsing', ',', 'and', 'semantic', 'reasoning', ',', 'wrappers', 'for', 'industrial-strength', 'NLP', 'libraries', ',', 'and', 'an', 'active', 'discussion', 'forum', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokens) #缩略词，标点，easy-to-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6f0b2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.csdn.net/qq_28790663/article/details/116719867\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd41ffdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize('saddest', 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7df344e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cars--n-->car\n",
      "men--n-->men\n",
      "running--v-->run\n",
      "ate--v-->eat\n",
      "saddest--a-->sad\n",
      "fancier--a-->fancy\n"
     ]
    }
   ],
   "source": [
    "#分别定义需要进行还原的单词与相对应的词性\n",
    "words = ['cars','men','running','ate','saddest','fancier']\n",
    "pos_tags = ['n','n','v','v','a','a']\n",
    " \n",
    "for i in range(len(words)):\n",
    "    print(words[i]+'--'+pos_tags[i]+'-->'+wnl.lemmatize(words[i],pos_tags[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2127e2",
   "metadata": {},
   "source": [
    "## 读取文本文件分析词频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fca3991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import MWETokenizer\n",
    "from nltk.corpus import wordnet\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59b2c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9f02d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(\"./data.txt\",encoding='utf-8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f64e7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "for t in text:\n",
    "    #去除标点符号\n",
    "    for c in string.punctuation:\n",
    "        if c !='-':\n",
    "            t = t.replace(c,' ')\n",
    "    #分词，添加自定义词组，去除停用词\n",
    "    tokenizer = MWETokenizer([('Python', 'programs'), ('a', 'little', 'bit'), ('a', 'lot')], separator = '-')\n",
    "    wordlist = tokenizer.tokenize(nltk.word_tokenize(t))\n",
    "    #wordlist = nltk.word_tokenize(t)\n",
    "    filtered = [w for w in wordlist if w not in stopwords.words('english')]\n",
    "    #标注词性\n",
    "    refiltered =nltk.pos_tag(filtered)\n",
    "    #词形还原\n",
    "    lemmas_sent = []\n",
    "    for wordtag in refiltered:\n",
    "        wordnet_pos = get_word_pos(wordtag[1]) or wordnet.NOUN\n",
    "        word = wnl.lemmatize(wordtag[0], pos=wordnet_pos)\n",
    "        lemmas_sent.append(word) # 词形还原\n",
    "        word_dict[word] = word_dict.get(word,0)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97eb82be",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordfreq = pd.DataFrame({'word':word_dict.keys(),'freq':word_dict.values()})\n",
    "wordfreq.to_excel(\"wordfreq.xlsx\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "754eee38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##处理前: NLTK has been called “a wonderful tool for teaching  and working in  computational linguistics using Python ” and “an amazing library to play with natural language ”\n",
      "##处理后: ['NLTK', 'call', '“', 'wonderful', 'tool', 'teach', 'work', 'computational', 'linguistics', 'use', 'Python', '”', '“', 'amaze', 'library', 'play', 'natural', 'language', '”']\n"
     ]
    }
   ],
   "source": [
    "print(\"##处理前:\",t)\n",
    "print(\"##处理后:\",lemmas_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7be6f633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NLTK</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lead</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>platform</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>build</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python-programs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Python</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>”</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>amaze</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>play</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>natural</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  freq\n",
       "0              NLTK     5\n",
       "1              lead     1\n",
       "2          platform     1\n",
       "3             build     1\n",
       "4   Python-programs     1\n",
       "..              ...   ...\n",
       "77           Python     1\n",
       "78                ”     2\n",
       "79            amaze     1\n",
       "80             play     1\n",
       "81          natural     1\n",
       "\n",
       "[82 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51498e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
